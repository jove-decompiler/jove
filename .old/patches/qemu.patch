diff --git a/target-arm/translate-a64.c b/target-arm/translate-a64.c
index b13cff756a..3209de76fa 100644
--- a/target-arm/translate-a64.c
+++ b/target-arm/translate-a64.c
@@ -2711,20 +2711,21 @@ static void disas_pc_rel_adr(DisasContext *s, uint32_t insn)
     offset = offset << 2 | extract32(insn, 29, 2);
     rd = extract32(insn, 0, 5);
     base = s->pc - 4;
 
     if (page) {
         /* ADRP (page based) */
         base &= ~0xfff;
         offset <<= 12;
     }
 
+    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
     tcg_gen_movi_i64(cpu_reg(s, rd), base + offset);
 }
 
 /*
  * C3.4.1 Add/subtract (immediate)
  *
  *  31 30 29 28       24 23 22 21         10 9   5 4   0
  * +--+--+--+-----------+-----+-------------+-----+-----+
  * |sf|op| S| 1 0 0 0 1 |shift|    imm12    |  Rn | Rd  |
  * +--+--+--+-----------+-----+-------------+-----+-----+
diff --git a/target-arm/translate.c b/target-arm/translate.c
index 940ec8d981..e97a8ca0e1 100644
--- a/target-arm/translate.c
+++ b/target-arm/translate.c
@@ -152,20 +152,21 @@ static inline void store_cpu_offset(TCGv_i32 var, int offset)
 /* Set a variable to the value of a CPU register.  */
 static void load_reg_var(DisasContext *s, TCGv_i32 var, int reg)
 {
     if (reg == 15) {
         uint32_t addr;
         /* normally, since we updated PC, we need only to add one insn */
         if (s->thumb)
             addr = (long)s->pc + 2;
         else
             addr = (long)s->pc + 4;
+        tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
         tcg_gen_movi_i32(var, addr);
     } else {
         tcg_gen_mov_i32(var, cpu_R[reg]);
     }
 }
 
 /* Create a new temporary and set it to the value of a CPU register.  */
 static inline TCGv_i32 load_reg(DisasContext *s, int reg)
 {
     TCGv_i32 tmp = tcg_temp_new_i32();
@@ -3955,20 +3956,21 @@ static int disas_vfp_insn(DisasContext *s, uint32_t insn)
             else
                 rd = VFP_SREG_D(insn);
             if ((insn & 0x01200000) == 0x01000000) {
                 /* Single load/store */
                 offset = (insn & 0xff) << 2;
                 if ((insn & (1 << 23)) == 0)
                     offset = -offset;
                 if (s->thumb && rn == 15) {
                     /* This is actually UNPREDICTABLE */
                     addr = tcg_temp_new_i32();
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                     tcg_gen_movi_i32(addr, s->pc & ~2);
                 } else {
                     addr = load_reg(s, rn);
                 }
                 tcg_gen_addi_i32(addr, addr, offset);
                 if (insn & (1 << 20)) {
                     gen_vfp_ld(s, dp, addr);
                     gen_mov_vreg_F0(dp, rd);
                 } else {
                     gen_mov_F0_vreg(dp, rd);
@@ -3994,20 +3996,21 @@ static int disas_vfp_insn(DisasContext *s, uint32_t insn)
                     return 1;
                 }
                 if (rn == 15 && w) {
                     /* writeback to PC is UNPREDICTABLE, we choose to UNDEF */
                     return 1;
                 }
 
                 if (s->thumb && rn == 15) {
                     /* This is actually UNPREDICTABLE */
                     addr = tcg_temp_new_i32();
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                     tcg_gen_movi_i32(addr, s->pc & ~2);
                 } else {
                     addr = load_reg(s, rn);
                 }
                 if (insn & (1 << 24)) /* pre-decrement */
                     tcg_gen_addi_i32(addr, addr, -((insn & 0xff) << 2));
 
                 if (dp)
                     offset = 8;
                 else
@@ -8279,20 +8282,21 @@ static void disas_arm_insn(DisasContext *s, unsigned int insn)
             }
             break;
         case 0x3:
             if (op1 != 1)
               goto illegal_op;
 
             ARCH(5);
             /* branch link/exchange thumb (blx) */
             tmp = load_reg(s, rm);
             tmp2 = tcg_temp_new_i32();
+            tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
             tcg_gen_movi_i32(tmp2, s->pc);
             store_reg(s, 14, tmp2);
             gen_bx(s, tmp);
             break;
         case 0x4:
         {
             /* crc32/crc32c */
             uint32_t c = extract32(insn, 8, 4);
 
             /* Check this CPU supports ARMv8 CRC instructions.
@@ -9326,20 +9330,21 @@ static void disas_arm_insn(DisasContext *s, unsigned int insn)
                                 loaded_base = 1;
                             } else {
                                 store_reg_from_load(s, i, tmp);
                             }
                         } else {
                             /* store */
                             if (i == 15) {
                                 /* special case: r15 = PC + 8 */
                                 val = (long)s->pc + 4;
                                 tmp = tcg_temp_new_i32();
+                                tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                                 tcg_gen_movi_i32(tmp, val);
                             } else if (user) {
                                 tmp = tcg_temp_new_i32();
                                 tmp2 = tcg_const_i32(i);
                                 gen_helper_get_user_reg(tmp, cpu_env, tmp2);
                                 tcg_temp_free_i32(tmp2);
                             } else {
                                 tmp = load_reg(s, i);
                             }
                             gen_aa32_st32(s, tmp, addr, get_mem_index(s));
@@ -9588,20 +9593,21 @@ static int disas_thumb2_insn(CPUARMState *env, DisasContext *s, uint16_t insn_hw
     case 0: case 1: case 2: case 3:
         /* 16-bit instructions.  Should never happen.  */
         abort();
     case 4:
         if (insn & (1 << 22)) {
             /* Other load/store, table branch.  */
             if (insn & 0x01200000) {
                 /* Load/store doubleword.  */
                 if (rn == 15) {
                     addr = tcg_temp_new_i32();
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                     tcg_gen_movi_i32(addr, s->pc & ~3);
                 } else {
                     addr = load_reg(s, rn);
                 }
                 offset = (insn & 0xff) * 4;
                 if ((insn & (1 << 23)) == 0)
                     offset = -offset;
                 if (insn & (1 << 24)) {
                     tcg_gen_addi_i32(addr, addr, offset);
                     offset = 0;
@@ -9642,39 +9648,41 @@ static int disas_thumb2_insn(CPUARMState *env, DisasContext *s, uint16_t insn_hw
                 if (insn & (1 << 20)) {
                     gen_load_exclusive(s, rs, 15, addr, 2);
                 } else {
                     gen_store_exclusive(s, rd, rs, 15, addr, 2);
                 }
                 tcg_temp_free_i32(addr);
             } else if ((insn & (7 << 5)) == 0) {
                 /* Table Branch.  */
                 if (rn == 15) {
                     addr = tcg_temp_new_i32();
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                     tcg_gen_movi_i32(addr, s->pc);
                 } else {
                     addr = load_reg(s, rn);
                 }
                 tmp = load_reg(s, rm);
                 tcg_gen_add_i32(addr, addr, tmp);
                 if (insn & (1 << 4)) {
                     /* tbh */
                     tcg_gen_add_i32(addr, addr, tmp);
                     tcg_temp_free_i32(tmp);
                     tmp = tcg_temp_new_i32();
                     gen_aa32_ld16u(s, tmp, addr, get_mem_index(s));
                 } else { /* tbb */
                     tcg_temp_free_i32(tmp);
                     tmp = tcg_temp_new_i32();
                     gen_aa32_ld8u(s, tmp, addr, get_mem_index(s));
                 }
                 tcg_temp_free_i32(addr);
                 tcg_gen_shli_i32(tmp, tmp, 1);
+                tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                 tcg_gen_addi_i32(tmp, tmp, s->pc);
                 store_reg(s, 15, tmp);
             } else {
                 int op2 = (insn >> 6) & 0x3;
                 op = (insn >> 4) & 0x3;
                 switch (op2) {
                 case 0:
                     goto illegal_op;
                 case 1:
                     /* Load/store exclusive byte/halfword/doubleword */
@@ -10586,20 +10594,21 @@ static int disas_thumb2_insn(CPUARMState *env, DisasContext *s, uint16_t insn_hw
                         }
                     } else {
                         /* Add/sub 12-bit immediate.  */
                         if (rn == 15) {
                             offset = s->pc & ~(uint32_t)3;
                             if (insn & (1 << 23))
                                 offset -= imm;
                             else
                                 offset += imm;
                             tmp = tcg_temp_new_i32();
+                            tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                             tcg_gen_movi_i32(tmp, offset);
                         } else {
                             tmp = load_reg(s, rn);
                             if (insn & (1 << 23))
                                 tcg_gen_subi_i32(tmp, tmp, imm);
                             else
                                 tcg_gen_addi_i32(tmp, tmp, imm);
                         }
                     }
                     store_reg(s, rd, tmp);
@@ -10706,20 +10715,21 @@ static int disas_thumb2_insn(CPUARMState *env, DisasContext *s, uint16_t insn_hw
         memidx = get_mem_index(s);
         if (rn == 15) {
             addr = tcg_temp_new_i32();
             /* PC relative.  */
             /* s->pc has already been incremented by 4.  */
             imm = s->pc & 0xfffffffc;
             if (insn & (1 << 23))
                 imm += insn & 0xfff;
             else
                 imm -= insn & 0xfff;
+            tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
             tcg_gen_movi_i32(addr, imm);
         } else {
             addr = load_reg(s, rn);
             if (insn & (1 << 23)) {
                 /* Positive offset.  */
                 imm = insn & 0xfff;
                 tcg_gen_addi_i32(addr, addr, imm);
             } else {
                 imm = insn & 0xff;
                 switch ((insn >> 8) & 0xf) {
@@ -10930,20 +10940,21 @@ static void disas_thumb_insn(CPUARMState *env, DisasContext *s)
             }
         }
         break;
     case 4:
         if (insn & (1 << 11)) {
             rd = (insn >> 8) & 7;
             /* load pc-relative.  Bit 1 of PC is ignored.  */
             val = s->pc + 2 + ((insn & 0xff) * 4);
             val &= ~(uint32_t)2;
             addr = tcg_temp_new_i32();
+            tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
             tcg_gen_movi_i32(addr, val);
             tmp = tcg_temp_new_i32();
             gen_aa32_ld32u(s, tmp, addr, get_mem_index(s));
             tcg_temp_free_i32(addr);
             store_reg(s, rd, tmp);
             break;
         }
         if (insn & (1 << 10)) {
             /* data processing extended or blx */
             rd = (insn & 7) | ((insn >> 4) & 8);
@@ -10967,20 +10978,21 @@ static void disas_thumb_insn(CPUARMState *env, DisasContext *s)
             case 2: /* mov/cpy */
                 tmp = load_reg(s, rm);
                 store_reg(s, rd, tmp);
                 break;
             case 3:/* branch [and link] exchange thumb register */
                 tmp = load_reg(s, rm);
                 if (insn & (1 << 7)) {
                     ARCH(5);
                     val = (uint32_t)s->pc | 1;
                     tmp2 = tcg_temp_new_i32();
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                     tcg_gen_movi_i32(tmp2, val);
                     store_reg(s, 14, tmp2);
                 }
                 /* already thumb, no need to check */
                 gen_bx(s, tmp);
                 break;
             }
             break;
         }
 
@@ -11263,20 +11275,21 @@ static void disas_thumb_insn(CPUARMState *env, DisasContext *s)
 
     case 10:
         /* add to high reg */
         rd = (insn >> 8) & 7;
         if (insn & (1 << 11)) {
             /* SP */
             tmp = load_reg(s, 13);
         } else {
             /* PC. bit 1 is ignored.  */
             tmp = tcg_temp_new_i32();
+            tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
             tcg_gen_movi_i32(tmp, (s->pc + 2) & ~(uint32_t)2);
         }
         val = (insn & 0xff) * 4;
         tcg_gen_addi_i32(tmp, tmp, val);
         store_reg(s, rd, tmp);
         break;
 
     case 11:
         /* misc */
         op = (insn >> 8) & 0xf;
diff --git a/target-i386/translate.c b/target-i386/translate.c
index 922347caf1..80be74ba4a 100644
--- a/target-i386/translate.c
+++ b/target-i386/translate.c
@@ -1865,20 +1865,21 @@ static AddressParts gen_lea_modrm_0(CPUX86State *env, DisasContext *s,
 
         switch (mod) {
         case 0:
             if ((base & 7) == 5) {
                 base = -1;
                 disp = (int32_t)cpu_ldl_code(env, s->pc);
                 s->pc += 4;
                 if (CODE64(s) && !havesib) {
                     base = -2;
                     disp += s->pc + s->rip_offset;
+                    tcg_gen_insn_start(0x7fffffff, 0x7fffffff);
                 }
             }
             break;
         case 1:
             disp = (int8_t)cpu_ldub_code(env, s->pc++);
             break;
         default:
         case 2:
             disp = (int32_t)cpu_ldl_code(env, s->pc);
             s->pc += 4;
@@ -2242,20 +2243,41 @@ static void gen_push_v(DisasContext *s, TCGv val)
             new_esp = cpu_tmp4;
             tcg_gen_mov_tl(new_esp, cpu_A0);
         }
         gen_lea_v_seg(s, a_ot, cpu_A0, R_SS, -1);
     }
 
     gen_op_st_v(s, d_ot, val, cpu_A0);
     gen_op_mov_reg_v(a_ot, R_ESP, new_esp);
 }
 
+/* Generate a push. It depends on ss32, addseg and dflag.  */
+static void gen_push_v_nost(DisasContext *s, TCGv val)
+{
+    TCGMemOp d_ot = mo_pushpop(s, s->dflag);
+    TCGMemOp a_ot = mo_stacksize(s);
+    int size = 1 << d_ot;
+    TCGv new_esp = cpu_A0;
+
+    tcg_gen_subi_tl(cpu_A0, cpu_regs[R_ESP], size);
+
+    if (!CODE64(s)) {
+        if (s->addseg) {
+            new_esp = cpu_tmp4;
+            tcg_gen_mov_tl(new_esp, cpu_A0);
+        }
+        gen_lea_v_seg(s, a_ot, cpu_A0, R_SS, -1);
+    }
+
+    gen_op_mov_reg_v(a_ot, R_ESP, new_esp);
+}
+
 /* two step pop is necessary for precise exceptions */
 static TCGMemOp gen_pop_T0(DisasContext *s)
 {
     TCGMemOp d_ot = mo_pushpop(s, s->dflag);
 
     gen_lea_v_seg(s, mo_stacksize(s), cpu_regs[R_ESP], R_SS, -1);
     gen_op_ld_v(s, d_ot, cpu_T0, cpu_A0);
 
     return d_ot;
 }
@@ -4851,21 +4873,21 @@ static target_ulong disas_insn(CPUX86State *env, DisasContext *s,
                 opreg = rm;
             gen_inc(s, ot, opreg, -1);
             break;
         case 2: /* call Ev */
             /* XXX: optimize if memory (no 'and' is necessary) */
             if (dflag == MO_16) {
                 tcg_gen_ext16u_tl(cpu_T0, cpu_T0);
             }
             next_eip = s->pc - s->cs_base;
             tcg_gen_movi_tl(cpu_T1, next_eip);
-            gen_push_v(s, cpu_T1);
+            gen_push_v_nost(s, cpu_T1);
             gen_op_jmp_v(cpu_T0);
             gen_bnd_jmp(s);
             gen_eob(s);
             break;
         case 3: /* lcall Ev */
             gen_op_ld_v(s, ot, cpu_T1, cpu_A0);
             gen_add_A0_im(s, 1 << ot);
             gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0);
         do_lcall:
             if (s->pe && !s->vm86) {
@@ -6333,21 +6355,21 @@ static target_ulong disas_insn(CPUX86State *env, DisasContext *s,
                 tval = (int16_t)insn_get(env, s, MO_16);
             }
             next_eip = s->pc - s->cs_base;
             tval += next_eip;
             if (dflag == MO_16) {
                 tval &= 0xffff;
             } else if (!CODE64(s)) {
                 tval &= 0xffffffff;
             }
             tcg_gen_movi_tl(cpu_T0, next_eip);
-            gen_push_v(s, cpu_T0);
+            gen_push_v_nost(s, cpu_T0);
             gen_bnd_jmp(s);
             gen_jmp(s, tval);
         }
         break;
     case 0x9a: /* lcall im */
         {
             unsigned int selector, offset;
 
             if (CODE64(s))
                 goto illegal_op;
